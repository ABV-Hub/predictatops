{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Example Notebook for Predictatops steps load & split\n",
    "updated Justin Gosses October 2019\n",
    "### Uses these modules of Predictatops:\n",
    "## 1. load.py\n",
    "## 2. split.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example_Every_Step_Via_HighLevel_Runner_Scripts_v1.ipynb\r\n",
      "Example_firstSteps_modules_fetchdata_configuration_checkdata.ipynb\r\n",
      "Example_module_balance_v1.ipynb\r\n",
      "Example_module_predictionclasses_v1.ipynb\r\n",
      "Example_module_trainclasses_v2.ipynb\r\n",
      "Example_module_wellsKNN_v1.ipynb\r\n",
      "README.md\r\n",
      "Untitled.ipynb\r\n",
      "current_errors_TopMcMr_20181006.png\r\n",
      "\u001b[34mmannville_demo_data\u001b[m\u001b[m/\r\n",
      "mannville_demo_data.zip\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/justingosses/Code/predictatops_temp/predictatops\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/justingosses/Code/predictatops_temp/predictatops/predictatops\n"
     ]
    }
   ],
   "source": [
    "cd predictatops/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py                       load.py\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m/                      load_runner.py\r\n",
      "all_runner.py                     main.py\r\n",
      "balance.py                        plot.py\r\n",
      "balance_runner.py                 plot_runner.py\r\n",
      "checkdata.py                      predictionclasses.py\r\n",
      "checkdata_runner.py               predictionclasses_runner.py\r\n",
      "cli.py                            registry_zip.txt\r\n",
      "configurationplusfiles.py         split.py\r\n",
      "configurationplusfiles_runner.py  split_runner.py\r\n",
      "features.py                       trainclasses.py\r\n",
      "features_runner.py                trainclasses_runner.py\r\n",
      "fetch_demo_data.py                wellsKNN.py\r\n",
      "fetch_demo_data_oldV1.py          wellsKNN_runner.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should be in the Predictatops source file and see various .py files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load import *\n",
    "from checkdata_runner import checkdata_path_results\n",
    "from configurationplusfiles_runner import input_data_inst, config, output_data_inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################ path_to_wells,file_ending ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dir = (\n",
    "    output_data_inst.base_path_for_all_results + \"/\" + output_data_inst.path_checkData\n",
    ")\n",
    "\n",
    "checkdata__file_path_for_results = checkdata_path_results\n",
    "\n",
    "max_numb_wells_to_load = config.max_numb_wells_to_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################ Load File of well names saved from running checkdata functions ###################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellNames_wTopsCuves_toLoad = pd.read_hdf(checkdata__file_path_for_results)\n",
    "print(\"wellNames_wTopsCuves_toLoad = \", wellNames_wTopsCuves_toLoad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of wells we want is: 1601\n",
      "examples of well names we'll try to find are:                      wells\n",
      "0  AA-10-26-078-08W4-0.LAS\n",
      "1  00-07-14-091-18W4-0.LAS\n",
      "2  00-03-18-082-12W4-0.LAS\n",
      "3  00-09-25-078-16W4-0.LAS\n"
     ]
    }
   ],
   "source": [
    "print(\"length of wells we want is:\", len(wellNames_wTopsCuves_toLoad))\n",
    "\n",
    "print(\"examples of well names we'll try to find are:\", wellNames_wTopsCuves_toLoad[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_wells = input_data_inst.las_folder_path\n",
    "file_ending = input_data_inst.well_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changes format of well list into a pandas dataframe with one column called \"UWI_file\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info for wells_df: type, columns, and length =  <class 'pandas.core.frame.DataFrame'> Index(['wells'], dtype='object') 1601\n"
     ]
    }
   ],
   "source": [
    "wells_df = wellNames_wTopsCuves_toLoad\n",
    "print(\n",
    "    \"info for wells_df: type, columns, and length = \",\n",
    "    type(wells_df),\n",
    "    wells_df.columns,\n",
    "    len(wells_df),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_wells_in_given_folder = find_number_well_files_in_a_folder(\n",
    "    path_to_wells, file_ending\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of wells found in  ../data/Mannville_input_data/v0.0.3-alpha/mannville_demo_data/OilSandsDB/Logs/ * .LAS  folder is  2171\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"number of wells found in \",\n",
    "    path_to_wells,\n",
    "    \"*\",\n",
    "    file_ending,\n",
    "    \" folder is \",\n",
    "    number_of_wells_in_given_folder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the wells for real now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loading the wells for real now\n",
    "initial_well_dict = load_all_wells_in(\n",
    "    wells_df, max_numb_wells_to_load, path_to_wells, file_ending\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> type dict_of_well_df_0\n"
     ]
    }
   ],
   "source": [
    "dict_of_well_df = initial_well_dict\n",
    "dict_of_well_df_0 = dict_of_well_df[0]\n",
    "print(type(dict_of_well_df_0), \"type dict_of_well_df_0\")\n",
    "# print(\"dict_of_well_df_0\",dict_of_well_df_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_failed_wells = initial_well_dict[1]\n",
    "#print(list_of_failed_wells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"length of wells we have determined have the tops and curves we desire is:\",\n",
    "    len(wellNames_wTopsCuves_toLoad),\n",
    ")\n",
    "print(\"len(list_of_failed_wells)\", len(list_of_failed_wells))\n",
    "print(\"len(dict_of_well_df[0])\", len(dict_of_well_df[0]))\n",
    "print(\n",
    "    \"length of all seen wells, which is failed and completed wells combined\",\n",
    "    len(set(list_of_failed_wells)) + len(dict_of_well_df[0]),\n",
    ")\n",
    "\n",
    "print(\"type(dict_of_well_df) = \", (type(dict_of_well_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = turn_dict_of_well_dfs_to_single_df(dict_of_well_df_0)\n",
    "\n",
    "print(\n",
    "    \"we now has all the wells we want in a single dataframe with \",\n",
    "    len(df_1[\"UWI\"].unique()),\n",
    "    \" unique UWI identifiers\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_wells_df_name_h5 = (\n",
    "    output_data_inst.base_path_for_all_results\n",
    "    + \"/\"\n",
    "    + output_data_inst.path_load\n",
    "    + \"/\"\n",
    "    + output_data_inst.loaded_results_wells_df\n",
    "    + output_data_inst.default_results_file_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save dataframe as hdf\n",
    "df_1.to_hdf(saved_wells_df_name_h5, key=\"df\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will move onto\n",
    "# Split.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from split import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from load_runner import saved_wells_df_name_h5\n",
    "from configurationplusfiles_runner import input_data_inst, config, output_data_inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################ path_to_wells,file_ending ###################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = output_data_inst.base_path_for_all_results + \"/\" + output_data_inst.path_load\n",
    "load_filename = output_data_inst.loaded_results_wells_df\n",
    "load_results_full_file_path = (\n",
    "    load_dir + \"/\" + load_filename + output_data_inst.default_results_file_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_numb_wells_to_load = config.max_numb_wells_to_load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Load File of well names saved from running checkdata functions ###################\n",
    "################ This file is wells loaded but no features or train test split yet ###################\n",
    "\n",
    "wells_df_from_load = pd.read_hdf(load_results_full_file_path)\n",
    "\n",
    "################ File that will be written at the end ###################\n",
    "\n",
    "\n",
    "################ configuration ###################\n",
    "split_variable = config.split_traintest_percent\n",
    "\n",
    "################ code ###################\n",
    "df_all_Col_preSplit_wTrainTest = split_train_test(\n",
    "    wells_df_from_load, split_variable, config.UWI\n",
    ")\n",
    "\n",
    "saved_split_wells_df_name_h5 = (\n",
    "    output_data_inst.base_path_for_all_results\n",
    "    + \"/\"\n",
    "    + output_data_inst.path_split\n",
    "    + \"/\"\n",
    "    + output_data_inst.split_results_wells_df\n",
    "    + output_data_inst.default_results_file_format\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save dataframe as hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_Col_preSplit_wTrainTest.to_hdf(saved_split_wells_df_name_h5, key=\"df\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:predictatops] *",
   "language": "python",
   "name": "conda-env-predictatops-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
