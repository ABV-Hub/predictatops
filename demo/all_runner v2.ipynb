{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking_for_right_len_in_balance.ipynb\r\n",
      "Junk - experimentation .ipynb\r\n",
      "Junk - experimentation 2.ipynb\r\n",
      "Junk - experimentation 3 - features & balance.ipynb\r\n",
      "Untitled.ipynb\r\n",
      "all_runner v1.ipynb\r\n",
      "all_runner v2.ipynb\r\n",
      "balance junk v1.ipynb\r\n",
      "current_errors_TopMcMr_20181006.png\r\n",
      "\u001b[34mmannville_demo_data\u001b[m\u001b[m/\r\n",
      "predictionclasses v1.ipynb\r\n",
      "test junk.ipynb\r\n",
      "trainclasses junk v1.ipynb\r\n",
      "trainclasses junk v2.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justingosses/anaconda/envs/predictatops/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/justingosses/anaconda/envs/predictatops/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/justingosses/Code/predictatops\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPG_Abstract_2019ACE.md\r\n",
      "AUTHORS.rst\r\n",
      "CONTRIBUTING.rst\r\n",
      "HISTORY.rst\r\n",
      "LICENSE\r\n",
      "MANIFEST.in\r\n",
      "Makefile\r\n",
      "README.md\r\n",
      "README.rst\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m/\r\n",
      "\u001b[34mdata\u001b[m\u001b[m/\r\n",
      "\u001b[34mdemo\u001b[m\u001b[m/\r\n",
      "\u001b[34mdocs\u001b[m\u001b[m/\r\n",
      "environment.yml\r\n",
      "environment_initial.yml\r\n",
      "\u001b[34mpredictatops\u001b[m\u001b[m/\r\n",
      "\u001b[34mpredictatops.egg-info\u001b[m\u001b[m/\r\n",
      "requirements.txt\r\n",
      "requirements_dev.txt\r\n",
      "\u001b[34mresults\u001b[m\u001b[m/\r\n",
      "\u001b[34mresults_higherBlanceAndLowerWindows_20190517\u001b[m\u001b[m/\r\n",
      "\u001b[34mresults_higherBlance_20190513\u001b[m\u001b[m/\r\n",
      "setup.cfg\r\n",
      "setup.py\r\n",
      "\u001b[34mtests\u001b[m\u001b[m/\r\n",
      "tox.ini\r\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/justingosses/Code/predictatops/predictatops\n"
     ]
    }
   ],
   "source": [
    "cd predictatops/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainclasses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-18 18:45:58.339774\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run everything!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from all_runner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-18 18:45:59.359068\n"
     ]
    }
   ],
   "source": [
    "### starting again \n",
    "import datetime\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictionclasses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of picks df =      SitID  HorID      Pick  Quality\n",
      "0  102496   1000       321        1\n",
      "1  102496   2000                 -1\n",
      "2  102496   3000                 -1\n",
      "3  102496   4000                 -1\n",
      "4  102496   5000       438        2\n",
      "making base folder for results in: ../results_higherBlanceAndLowerWindows_20190517\n",
      "base_path directory already exists, ../results_higherBlanceAndLowerWindows_20190517  so not creating it again. This may or may not be what you intended, so just flagging it.\n",
      "directory  checkData  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  load  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  split  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  wellsKNN  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  features  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  balance  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  trainclasses  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  prediction  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  evaluate  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  map  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "made directories for each step in the process. They should be in :  ../results_higherBlanceAndLowerWindows_20190517\n",
      "must have curve list is:  ['ILD', 'NPHI', 'GR', 'DPHI', 'DEPT']\n",
      "set must_have_tops_list as:  [13000, 14000]\n",
      " set self.top_name_col_in_picks_df as:  HorID\n",
      "config.siteID_col_in_picks_df =  SitID\n",
      "all config is {'csv_of_well_names_wTopsCuves__name': '', 'csv_of_well_names_wTopCurves__path': '.', 'must_have_curves_list': ['ILD', 'NPHI', 'GR', 'DPHI', 'DEPT'], 'curve_windows_for_rolling_features': [3, 5, 11, 21], 'must_have_tops__list': [13000, 14000], 'target_top': 13000, 'top_under_target': 14000, 'top_name_col_in_picks_df': 'HorID', 'siteID_col_in_picks_df': 'SitID', 'UWI': 'UWI', 'DEPTH_col_in_featureCreation': 'DEPT', 'HorID_name_col_in_picks_df': 'HorID', 'quality_col_name_in_picks_df': 'Quality', 'picks_depth_col_in_picks_df': 'Pick', 'col_topTarget_Depth_predBy_NN1thick': 'topTarget_Depth_predBy_NN1thick', 'quality_items_to_skip__list': [-1, 0], 'test': 'test0', 'pick_class_str': 'TopTarget_Pick_pred', 'threshold_returnCurvesThatArePresentInThisManyWells': 2000, 'max_numb_wells_to_load': 1000000, 'split_traintest_percent': 0.8, 'kdtree_leaf': 2, 'kdtree_k': 8, 'rebalanceClassZeroMultiplier': 120, 'rebalanceClass95Multiplier': 60, 'NN1_topTarget_DEPTH': 'NN1_topTarget_DEPTH', 'NN1_TopHelper_DEPTH': 'NN1_TopHelper_DEPTH', 'trainOrTest': 'trainOrTest', 'colsToNotTurnToFloats': ['UWI', 'SitID', 'trainOrTest', 'Neighbors_Obj'], 'zonesAroundTops': {'100': [0], '95': [-0.5, 0.5], '60': [-5, 0.5], '70': [0.5, 5], '0': []}, 'columns_to_not_trainOn_andNotCurves': ['FromBotWell', 'FromTopWelrowsToEdge', 'lat', 'lng', 'SitID', 'TopHelper_HorID', 'TopTarget_HorID', 'TopHelper_DEPTH', 'diff_Top_Depth_Real_v_predBy_NN1thick', 'diff_TopTarget_DEPTH_v_rowDEPT', 'diff_TopHelper_DEPTH_v_rowDEPT', 'class_DistFrPick_TopHelper', 'NewWell', 'LastBitWell', 'TopWellDept', 'BotWellDept', 'WellThickness', 'rowsToEdge', 'closTopBotDist', 'closerToBotOrTop', 'Neighbors_Obj'], 'columns_to_not_trainOn_andAreCurves': ['RHOB', 'SP', 'CALI', 'COND', 'DELT', 'DENS', 'DPHI:1', 'DPHI:2', 'DT', 'GR:1', 'GR:2', 'IL', 'ILD:1', 'ILD:2', 'ILM', 'LITH', 'LLD', 'LLS', 'PHID', 'PHIN', 'RESD', 'RT', 'SFL', 'SFLU', 'SN', 'SNP', 'Sp'], 'columns_to_use_as_labels': ['class_DistFrPick_TopTarget', 'UWI', 'trainOrTest', 'TopTarget_DEPTH']}\n"
     ]
    }
   ],
   "source": [
    "from predictionclasses import *\n",
    "from predictionclasses import loadMLinstanceAndModel\n",
    "from configurationplusfiles_runner import input_data_inst, config, output_data_inst\n",
    "from main import getJobLibPickleResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loadMLinstanceAndModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ce8134cafefe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpredictionclasses_runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/predictatops/predictatops/predictionclasses_runner.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ML1 = getJobLibPickleResults(output_data_inst,output_data_inst.path_trainclasses,\"trainclasses_ML1_instance.pkl\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mML1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mloadMLinstanceAndModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_data_inst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loadMLinstanceAndModel' is not defined"
     ]
    }
   ],
   "source": [
    "import predictionclasses_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model imported is: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=nan, n_estimators=100,\n",
      "       n_gpus=0, n_jobs=-1, nthread=None, num_class=5,\n",
      "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justingosses/anaconda/envs/predictatops/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of training dataset 0.8435949167056516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justingosses/anaconda/envs/predictatops/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of test dataset 0.9170003556799798\n",
      "loaded model into object instance\n",
      " eventually there will some sort of help printed here to explain this function more and how it is envisioned you wil run it. In other words, step 1, step 2, etc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justingosses/anaconda/envs/predictatops/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran predict_from_model() which runs inside self.result_df_dist_class_prediction = model.predict(df_X_toPredict) access the results by appending .result_df_dist_class_prediction to the class instance\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "in concat_step2, type of df_results_trainOrtest_wIndex= <class 'pandas.core.frame.DataFrame'>\n",
      "type(idx) <class 'pandas.core.frame.DataFrame'>\n",
      "distClassDF_wRollingCols_training.head() =    class_DistFrPick_TopTarget TopTarget_Pick_pred class_DistFrPick_TopTarget                  UWI trainOrTest  TopTarget_DEPTH     DEPT  NN1_TopHelper_DEPTH  NN1_thickness  topTarget_Depth_predBy_NN1thick  DistFrom_NN1ThickPredTopDepth_toRowDept  TopTarget_Pick_pred_classRollMean3  TopTarget_Pick_pred_classRollMean5  TopTarget_Pick_pred_classRollMean11  TopTarget_Pick_pred_classRollMean21  TopTarget_Pick_predclassRollMeanSum  TopTarget_Pick_pred_DEPT_pred  TopTarget_Pick_pred_classRollMeanSum\n",
      "0                          0                   0                          0  00-10-32-080-20W4-0       train           377.95  149.602                414.0           25.0                           359.66                                  210.058                                 0.0                                 0.0                                  0.0                                  0.0                                  0.0                        358.102                             470.47619\n",
      "1                          0                   0                          0  00-10-32-080-20W4-0       train           377.95  149.852                414.0           25.0                           359.66                                  209.808                                 0.0                                 0.0                                  0.0                                  0.0                                  0.0                        358.102                             470.47619\n",
      "2                          0                   0                          0  00-10-32-080-20W4-0       train           377.95  150.102                414.0           25.0                           359.66                                  209.558                                 0.0                                 0.0                                  0.0                                  0.0                                  0.0                        358.102                             470.47619\n",
      "3                          0                   0                          0  00-10-32-080-20W4-0       train           377.95  150.352                414.0           25.0                           359.66                                  209.308                                 0.0                                 0.0                                  0.0                                  0.0                                  0.0                        358.102                             470.47619\n",
      "4                          0                   0                          0  00-10-32-080-20W4-0       train           377.95  150.602                414.0           25.0                           359.66                                  209.058                                 0.0                                 0.0                                  0.0                                  0.0                                  0.0                        358.102                             470.47619\n",
      "printing distClassDF_wRollingCols_training for checking that it makes sense::         class_DistFrPick_TopTarget TopTarget_Pick_pred class_DistFrPick_TopTarget                  UWI trainOrTest  TopTarget_DEPTH    DEPT  NN1_TopHelper_DEPTH  NN1_thickness  topTarget_Depth_predBy_NN1thick  DistFrom_NN1ThickPredTopDepth_toRowDept  TopTarget_Pick_pred_classRollMean3  TopTarget_Pick_pred_classRollMean5  TopTarget_Pick_pred_classRollMean11  TopTarget_Pick_pred_classRollMean21  TopTarget_Pick_predclassRollMeanSum  TopTarget_Pick_pred_DEPT_pred  TopTarget_Pick_pred_classRollMeanSum\n",
      "1374458                         95                  95                         95  00-10-35-081-15W4-0       train            321.0  320.75                323.5           23.0                            325.0                                     4.25                                95.0                                95.0                                  0.0                                  0.0                                285.0                          315.0                                 475.0\n",
      "1374459                         95                  95                         95  00-10-35-081-15W4-0       train            321.0  321.25                323.5           23.0                            325.0                                     3.75                                95.0                                95.0                                  0.0                                  0.0                                285.0                          315.0                                 475.0\n",
      "1374460                         95                  95                         95  00-10-35-081-15W4-0       train            321.0  320.50                323.5           23.0                            325.0                                     4.50                                 0.0                                 0.0                                  0.0                                  0.0                                 95.0                          315.0                                 475.0\n",
      "1374461                         95                  95                         95  00-10-35-081-15W4-0       train            321.0  320.75                323.5           23.0                            325.0                                     4.25                                 0.0                                 0.0                                  0.0                                  0.0                                 95.0                          315.0                                 475.0\n",
      "1374462                         95                  95                         95  00-10-35-081-15W4-0       train            321.0  321.25                323.5           23.0                            325.0                                     3.75                                 0.0                                 0.0                                  0.0                                  0.0                                 95.0                          315.0                                 475.0\n",
      "loaded model into object instance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justingosses/anaconda/envs/predictatops/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran predict_from_model() which runs inside self.result_df_dist_class_prediction = model.predict(df_X_toPredict) access the results by appending .result_df_dist_class_prediction to the class instance\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "in concat_step2, type of df_results_trainOrtest_wIndex= <class 'pandas.core.frame.DataFrame'>\n",
      "type of dist_class_pred_df <class 'pandas.core.frame.DataFrame'>\n",
      "type of self.df_results_trainOrtest_wIndex <class 'pandas.core.frame.DataFrame'>\n",
      "type(idx) <class 'pandas.core.frame.DataFrame'>\n",
      "distClassDF_wRollingCols_testData.head()   class_DistFrPick_TopTarget TopTarget_Pick_pred class_DistFrPick_TopTarget                  UWI trainOrTest  TopTarget_DEPTH    DEPT  NN1_TopHelper_DEPTH  NN1_thickness  topTarget_Depth_predBy_NN1thick  DistFrom_NN1ThickPredTopDepth_toRowDept  TopTarget_Pick_pred_classRollMean3  TopTarget_Pick_pred_classRollMean5  TopTarget_Pick_pred_classRollMean11  TopTarget_Pick_pred_classRollMean21  TopTarget_Pick_predclassRollMeanSum  TopTarget_Pick_pred_DEPT_pred  TopTarget_Pick_pred_classRollMeanSum\n",
      "0                          0                   0                          0  AA-11-33-094-06W4-0        test            272.0  100.00                294.5           62.5                            262.5                                   162.50                                 0.0                                 0.0                                  0.0                                  0.0                                  0.0                          271.0                                 475.0\n",
      "1                          0                   0                          0  AA-11-33-094-06W4-0        test            272.0  100.25                294.5           62.5                            262.5                                   162.25                                 0.0                                 0.0                                  0.0                                  0.0                                  0.0                          271.0                                 475.0\n",
      "2                          0                   0                          0  AA-11-33-094-06W4-0        test            272.0  100.50                294.5           62.5                            262.5                                   162.00                                 0.0                                 0.0                                  0.0                                  0.0                                  0.0                          271.0                                 475.0\n",
      "3                          0                   0                          0  AA-11-33-094-06W4-0        test            272.0  100.75                294.5           62.5                            262.5                                   161.75                                 0.0                                 0.0                                  0.0                                  0.0                                  0.0                          271.0                                 475.0\n",
      "4                          0                   0                          0  AA-11-33-094-06W4-0        test            272.0  101.00                294.5           62.5                            262.5                                   161.50                                 0.0                                 0.0                                  0.0                                  0.0                                  0.0                          271.0                                 475.0\n",
      "vs {'depth_str': 'DEPT', 'pick_class_str': 'TopTarget_Pick_pred', 'UWI_str': 'UWI', 'rollingWindows': [3, 5, 11, 21], 'distClassIntegersArray': ['100', '95', '60', '70', '0']}\n",
      "gap\n",
      "vs DEPT\n",
      "hit pass in optionallyExcludeWellsWithoutStrongPredictions()\n",
      "1\n",
      "2\n",
      "4\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "len(df_calc_pred_Top_Pick_pred_DEPT_pred 1280\n",
      "r2 of training dataset in terms of pick depths =  0.8606890328826061\n",
      "mean_absolute_error_ of training dataset in terms of pick depths =  14.786455468749898\n",
      "percent of wells kept because they weren't just class zero in rollToWell function for training: 1.0\n",
      "hit pass in optionallyExcludeWellsWithoutStrongPredictions()\n",
      "1\n",
      "2\n",
      "4\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "r2 for test and all wells kept is: 0.8732155566157629\n",
      "mean_absolute_error_test for test and all wells kept is: 16.779090342679012\n",
      "percent wells kept for test and all wells kept is: 1.0\n",
      "hit yes in optionallyExcludeWellsWithoutStrongPredictions()\n",
      "1\n",
      "2\n",
      "4\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "r2 for test and wells excluded that only had zero class predicted is: 0.9951091492184837\n",
      "mean_absolute_error_test for test and wells excluded that only had zero class predicted is: 7.344234323432155\n",
      "percent wells kept for test and wells excluded that only had zero class predicted is: 0.9439252336448598\n",
      "number of wells with only zeros predicted that were thrown out: 18.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################## Load model & ML class instance from trainclasses step #############\n",
    "\n",
    "# model = getJobLibPickleResults(output_data_inst,output_data_inst.path_trainclasses,\"trainclasses_model.pkl\")\n",
    "# ML1 = getJobLibPickleResults(output_data_inst,output_data_inst.path_trainclasses,\"trainclasses_ML1_instance.pkl\")\n",
    "\n",
    "model,ML1 =loadMLinstanceAndModel(output_data_inst)\n",
    "\n",
    "\n",
    "print(\"the model imported is:\",model)\n",
    "\n",
    "################## Class Prediction Results for training dataframe for X #############\n",
    "\n",
    "##### Creating a class_accuracy instance with the already established ML1 variable for an isntance of the ML_obj_class\n",
    "ac = class_accuracy(ML1)\n",
    "\n",
    "\n",
    "################## First with training data #############\n",
    "\n",
    "#### Running the accuracy calculation using the model trained on training data against training data. \n",
    "#### Testing how well the model predicts the class of each point, with class being categorized distance from actual pick.\n",
    "accuracy_train = ac.run_all(model,ac.train_X,ac.train_y,'TopTarget_Pick_pred','class_DistFrPick_TopTarget')\n",
    "\n",
    "print(\"accuracy of training dataset\",accuracy_train)\n",
    "\n",
    "\n",
    "################## Then with test data ###############\n",
    "\n",
    "#### Running the accuracy calculation using the model trained on training data against TEST data. \n",
    "#### Testing how well the model predicts the class of each point, with class being categorized distance from actual pick.\n",
    "accuracy_test = ac.run_all(model,ac.test_X,ac.test_y,'TopTarget_Pick_pred','class_DistFrPick_TopTarget')\n",
    "\n",
    "print(\"accuracy of test dataset\",accuracy_test)\n",
    "\n",
    "\n",
    "####################################### THIS IS TEST FOR ACCURACY OVER ALL ROWS, WHICH WE REALLY DON\"T CARE ABOUT ##########\n",
    "############ WE CARE ABOUT THE PICK ############################\n",
    "\n",
    "# New class for functions that take in point by point distance class prediction and use rolling window and other methods to pick which point should be the top in question\n",
    "# Make a few different columns classifiers that get the rolling mean of pick classifiers within different windows.\n",
    "# This will help compare a class prediction of 95 in one part of the well to a class prediction of 95 in a nother part of the well. The assumption being the right prediction will have not just one 100 or 95 prediction but several in close proximity where as the false predictions are more likely to be by themselves:\n",
    "\n",
    "#     Median\n",
    "#     Rolling mean 6\n",
    "#     Rolling mean 12\n",
    "#     Rolling Mean 20\n",
    "#     Sums of rolling all means\n",
    "\n",
    "\n",
    "concatClass = InputDistClassPrediction_to_BestDepthForTop(output_data_inst)\n",
    "\n",
    "concatClass.load_MLobj(ML1)\n",
    "\n",
    "concatClass.help()\n",
    "\n",
    "prediction_distClass_trainingData_ndarray = concatClass.predict_from_model(model,ML1.train_X)\n",
    "\n",
    "concatClass1 = concatClass.concat_modelResultsNDArray_w_indexValues(concatClass.result_df_dist_class_prediction,\"train\",config.pick_class_str)\n",
    "\n",
    "\n",
    "##### NEED TO PUT THIS LIST IN CONFIG ########## !!!!!!!\n",
    "cols_to_keep_list = ['DEPT',\"NN1_TopHelper_DEPTH\",\"NN1_thickness\",\"topTarget_Depth_predBy_NN1thick\",\"DistFrom_NN1ThickPredTopDepth_toRowDept\"]\n",
    "\n",
    "concatClass2 = concatClass.concat_step2(ML1,\"train\",cols_to_keep_list)\n",
    "\n",
    "#####\n",
    "DEPTH_col_in_featureCreation = config.DEPTH_col_in_featureCreation\n",
    "pick_class_str = config.pick_class_str\n",
    "UWI = config.UWI\n",
    "curve_windows_for_rolling_features = config.curve_windows_for_rolling_features\n",
    "label_intergers = list(config.zonesAroundTops.keys())\n",
    "\n",
    "distClassDF_wRollingCols_training = concatClass.calc_pred_vs_real_top_dif(concatClass.df_results_trainOrtest_wIndex,DEPTH_col_in_featureCreation,pick_class_str,UWI,curve_windows_for_rolling_features,label_intergers)\n",
    "\n",
    "\n",
    "print(\"distClassDF_wRollingCols_training.head() = \",distClassDF_wRollingCols_training.head())\n",
    "\n",
    "print(\"printing distClassDF_wRollingCols_training for checking that it makes sense::\",distClassDF_wRollingCols_training.tail())\n",
    "\n",
    "################ Now lets run test version   ################\n",
    "\n",
    "concatClass_test = InputDistClassPrediction_to_BestDepthForTop(output_data_inst)\n",
    "\n",
    "\n",
    "#####\n",
    "DEPTH_col_in_featureCreation = config.DEPTH_col_in_featureCreation\n",
    "pick_class_str = config.pick_class_str\n",
    "UWI = config.UWI\n",
    "curve_windows_for_rolling_features = config.curve_windows_for_rolling_features\n",
    "label_intergers = list(config.zonesAroundTops.keys())\n",
    "\n",
    "\n",
    "\n",
    "#### Doing it the 'all at once' way this time.\n",
    "distClassDF_wRollingCols_testData = concatClass_test.run_all(ML1,model,\"test\",cols_to_keep_list,DEPTH_col_in_featureCreation,pick_class_str,UWI,curve_windows_for_rolling_features,label_intergers)\n",
    "\n",
    "print(\"distClassDF_wRollingCols_testData.head()\",distClassDF_wRollingCols_testData.head())\n",
    "\n",
    "##################### The next part will attempt to go from classifiers of  ##################### \n",
    "#####################  (at, near, or far away from the pick in each well) to a single depth prediction for the pick in each well ###################### \n",
    "#####################  Class for calculating accuracy of single pick prediction in each well vs. #####################  \n",
    "######################  known pick based on rolling average & median ranking of depths with distance class #####################  \n",
    "#####################  predictions of being close to pick. #####################  \n",
    "\n",
    "vs = {\"depth_str\":config.DEPTH_col_in_featureCreation,\"pick_class_str\":config.pick_class_str,\"UWI_str\" :config.UWI,\"rollingWindows\":config.curve_windows_for_rolling_features,\"distClassIntegersArray\" :list(config.zonesAroundTops.keys())}\n",
    "print(\"vs\",vs)\n",
    "print(\"gap\")\n",
    "print(\"vs\",vs[\"depth_str\"])\n",
    "\n",
    "\n",
    "#####################  Start accuracy_singleTopPerWellPrediction_fromRollingRules() class for training data  #####################  \n",
    "\n",
    "rollToWell = accuracy_singleTopPerWellPrediction_fromRollingRules(ML1,vs,distClassDF_wRollingCols_training)\n",
    "\n",
    "r2,mean_absolute_error_,df_calc_pred_Top_Pick_pred_DEPT_pred = rollToWell.run_all('TopTarget_Pick_pred_DEPT_pred','TopTarget_DEPTH',keepAllWells=\"yes\",dropIfOnlyClasses=[0])\n",
    "\n",
    "\n",
    "print(\"len(df_calc_pred_Top_Pick_pred_DEPT_pred\",len(df_calc_pred_Top_Pick_pred_DEPT_pred))\n",
    "print(\"r2 of training dataset in terms of pick depths = \",r2)\n",
    "print(\"mean_absolute_error_ of training dataset in terms of pick depths = \",mean_absolute_error_)\n",
    "\n",
    "print(\"percent of wells kept because they weren't just class zero in rollToWell function for training:\",rollToWell.precentWellsKept)\n",
    "\n",
    "#####################  Now accuracy for test dataset again via accuracy_singleTopPerWellPrediction_fromRollingRules()  #####################  \n",
    "\n",
    "#####################  First we'll do it and keep all wells not matter whether or not they include any class predictions other than zero  #####################  \n",
    "#####################  This will include some wells with some very bad predictions as there are not class predictions to go off of #####################  \n",
    "\n",
    "\n",
    "rollToWell_test = accuracy_singleTopPerWellPrediction_fromRollingRules(ML1,vs,distClassDF_wRollingCols_testData)\n",
    "r2_test,mean_absolute_error_test,df_calc_pred_Top_Pick_pred_DEPT_pred2 = rollToWell_test.run_all('TopTarget_Pick_pred_DEPT_pred','TopTarget_DEPTH',keepAllWells=\"yes\",dropIfOnlyClasses=[0])\n",
    "\n",
    "print(\"r2 for test and all wells kept is:\",r2_test)\n",
    "print(\"mean_absolute_error_test for test and all wells kept is:\",mean_absolute_error_test)\n",
    "print(\"percent wells kept for test and all wells kept is:\",rollToWell_test.precentWellsKept)\n",
    "\n",
    "#####################  Now let's try it for test dataset but exclude wells that only have a zero class prediction #####################  \n",
    "\n",
    "rollToWell_test_NoZeros = accuracy_singleTopPerWellPrediction_fromRollingRules(ML1,vs,distClassDF_wRollingCols_testData)\n",
    "r2_test_NoZeros ,mean_absolute_error_test_NoZeros ,df_calc_pred_Top_Pick_pred_DEPT_pred2_NoZeros  = rollToWell_test_NoZeros .run_all('TopTarget_Pick_pred_DEPT_pred','TopTarget_DEPTH',keepAllWells=\"no\",dropIfOnlyClasses=[0])\n",
    "\n",
    "print(\"r2 for test and wells excluded that only had zero class predicted is:\",r2_test_NoZeros)\n",
    "print(\"mean_absolute_error_test for test and wells excluded that only had zero class predicted is:\",mean_absolute_error_test_NoZeros)\n",
    "print(\"percent wells kept for test and wells excluded that only had zero class predicted is:\",rollToWell_test_NoZeros.precentWellsKept)\n",
    "\n",
    "number_of_wells_thrown_out = len(rollToWell_test_NoZeros.fullUWIsSet) - len(rollToWell_test_NoZeros.fullUWIsSet)*rollToWell_test_NoZeros.precentWellsKept\n",
    "\n",
    "print(\"number of wells with only zeros predicted that were thrown out:\",number_of_wells_thrown_out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "################ import from other python files in this package ###################\n",
    "from trainclasses import *\n",
    "from configurationplusfiles_runner import input_data_inst, config, output_data_inst\n",
    "from main import get_df_results_from_step_X, getMainDFsavedInStep, load_prev_results_at_path\n",
    "\n",
    "\n",
    "\n",
    "## pandas Options to be run so everything displays properly\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "# pd.options.display.max_colwidth = 100000\n",
    "\n",
    "#### Optional checks\n",
    "# print(welly.__version__)\n",
    "# print(dask.__version__)\n",
    "# print(pd.__version__)\n",
    "# 0.3.5\n",
    "# 0.18.2\n",
    "# 0.23.3\n",
    "\n",
    "\n",
    "###### LOAD RESULTS DATAFRAME IN HD5 FROM BALANCE PORTION OF WORKFLOW ###########\n",
    "\n",
    "##### OLD STYLE #########\n",
    "\n",
    "# knn_dir = \"../WellsKNN/\"\n",
    "# load_dir = \"../loadLAS\"\n",
    "# features_dir = \"../createFeatures/\"\n",
    "# machine_learning_dir = \"../Pre_ML_Rebalance_Splitting/\"\n",
    "# h5_to_load = 'df_all_Col_preSplit_wTrainTest_ClassBalanced_PreML_20181003.h5'\n",
    "\n",
    "# ML1 = ML_obj_class(knn_dir,load_dir,features_dir,machine_learning_dir,h5_to_load )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ML1 = ML_obj_class(output_data_inst)\n",
    "\n",
    "# ML1.knn_dir\n",
    "\n",
    "ML1.load_data_for_ml()\n",
    "###ML1.dropNeighbors_ObjCol(\"Neighbors_Obj\")\n",
    "\n",
    "print(\"printing the preSplitpreBal df head that was saved in the balance part of the workflow.\")\n",
    "ML1.preSplitpreBal.head()\n",
    "\n",
    "# ML1.preSplitpreBal = ML1.preSplitpreBal[0:50000]\n",
    "# ML1.train_X = ML1.train_X[0:50000]\n",
    "# ML1.train_y = ML1.train_y[0:50000]\n",
    "# ML1.test_X = ML1.test_X[0:50000]\n",
    "# ML1.test_y = ML1.test_y[0:50000]\n",
    "print(\"ML1.train_X.columns\",ML1.train_X.columns)\n",
    "\n",
    "print(\"Now starting to make the model. If none given, parameters that worked well for the top McMurray pick will be used.\")\n",
    "print(\"default model parameters provided are: gamma=0, reg_alpha=0.3, max_depth=6, subsample=0.8, colsample_bytree= 0.8, n_estimators= 300, learning_rate= 0.03, min_child_weight= 3,n_jobs=8\")\n",
    "\n",
    "model = ML1.init_XGBoost_withSettings()\n",
    "\n",
    "print(\"now fitting the model to the training data:\")\n",
    "model.fit(ML1.train_X,ML1.train_y)\n",
    "\n",
    "############ just to show what model contains a bit  ###########\n",
    "\n",
    "print(\"just to show what model contains a bit:\")\n",
    "\n",
    "print(\"type(model)\",type(model))\n",
    "\n",
    "print(\"model stats\",model)\n",
    "\n",
    "print(\"model.subsample\",model.subsample)\n",
    "\n",
    "############   Optionally loading the already trained model here if it already exists locally.   ############ \n",
    "############   It can take quite a while to fit the model, so sometimes easier to save a copy and then load it.   ############ \n",
    "\n",
    "######################### WRITE FUNCTION FOR THIS !!!!!! ####################\n",
    "######################### Something like: model = pickle.load(open(\"classModel_20181122a.pickle.dat\", \"rb\")) & print(type(model))\n",
    "\n",
    "#model = pickle.load(open(\"classModel_20181122a.pickle.dat\", \"rb\")) & print(type(model))\n",
    "\n",
    "saveTrainClassesResultsAsPickle(model,ML1,output_data_inst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import trainclasses_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictionclasses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(predictionclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = loadMLinstanceAndModel(output_data_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../predictatops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictionclasses_runner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################ imports ###################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import welly\n",
    "from welly import Well\n",
    "import lasio\n",
    "import glob\n",
    "from sklearn import neighbors\n",
    "import pickle\n",
    "import math\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "import random\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import multiprocessing\n",
    "\n",
    "from main import getJobLibPickleResults\n",
    "#### Adding this bit to silence an error that was causing the notebook to have a dead kernal\n",
    "#### This is an unsafe solution but couldn't get any  of the \"right solutions\" to work!\n",
    "#### Ended up using this = https://www.kaggle.com/c/bosch-production-line-performance/discussion/25082\n",
    "#### Other solutions = https://github.com/dmlc/xgboost/issues/1715 but the solution here didn't seem to work for me?\n",
    "import os\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    "################## Class Prediction Results for training dataframe for X #############\n",
    "def loadMLinstanceAndModel(output_data_inst):\n",
    "    model = getJobLibPickleResults(output_data_inst,output_data_inst.path_trainclasses,\"trainclasses_model.pkl\")\n",
    "    ML1 = getJobLibPickleResults(output_data_inst,output_data_inst.path_trainclasses,\"trainclasses_ML1_instance.pkl\")\n",
    "    return model,ML1\n",
    "\n",
    "\n",
    "class class_accuracy():\n",
    "    \"\"\"\n",
    "    This class holds several functions for calculating accuracy of the class-identification model\n",
    "    It takes in as the initiation argument, an instance of the ML_obj_class, which contains all the \n",
    "    necessary data already processed with features created and ready to do for the machine-learning task.\n",
    "    It initiates on creation a variety of class instance attributes that mirror those created in the ML_obj_class class.\n",
    "    There are 5 functions. The help function will print some explanitory text. \n",
    "    The rest proceed to predict a dataframe from a trained model, reformat some of the input data so\n",
    "    it can be combined, calculate accuracy, and a final function that runs the last three if you don't want to\n",
    "    run them individually. \n",
    "    The last two functions will return an accuracy nubmer as a percentage of class rows or instances the model predicted corrected.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, ML):\n",
    "        # self.knn_dir = ML.knn_dir\n",
    "        # self.load_dir = ML.load_dir\n",
    "        # self.features_dir = ML.features_dir\n",
    "        self.machine_learning_dir = ML.machine_learning_dir\n",
    "        self.h5_to_load = ML.h5_to_load \n",
    "        self.train_X = ML.train_X\n",
    "        self.train_y = ML.train_y\n",
    "        self.test_X = ML.test_X\n",
    "        self.test_y = ML.test_y\n",
    "        self.train_index = ML.train_index\n",
    "        self.test_index = ML.test_index\n",
    "        self.preSplitpreBal = ML.preSplitpreBal\n",
    "        self.result_df_from_prediction = None\n",
    "    \n",
    "    def help(self):\n",
    "        print(\" eventually there will some sort of help printed here to explain this function more and how it is envisioned you wil run it. In other words, step 1, step 2, etc.\")\n",
    "        \n",
    "    def predict_from_model(self,model,df_X_toPredict):\n",
    "        \"\"\"\n",
    "        The predict_from_model function takes as argument a model that is already trained on training data, in the demo case a \n",
    "        scikit-learn XGBoost model and the dataframe of the columns to predict. From this, it fills in \n",
    "        the self.result_df_from_prediction attribute and returns nothing.\n",
    "    \n",
    "        \"\"\"\n",
    "        self.result_df_from_prediction = model.predict(df_X_toPredict)\n",
    "        \n",
    "    def first_Reformat(self,train_y,TopTarget_Pick_pred):\n",
    "        train_y_indexValues = train_y.index.values\n",
    "        df_result_train = pd.DataFrame(self.result_df_from_prediction, index=train_y_indexValues, columns=[TopTarget_Pick_pred])\n",
    "        df_results_train_ = pd.concat([train_y, df_result_train], axis=1)\n",
    "        return df_results_train_\n",
    "    \n",
    "    def accuracy_calc(self,train_y,TopTarget_Pick_pred,class_DistFrPick_TopTarget):\n",
    "        df_results_train_ = self.first_Reformat(train_y,TopTarget_Pick_pred)\n",
    "        accuracy = accuracy_score(df_results_train_[class_DistFrPick_TopTarget], df_results_train_[TopTarget_Pick_pred])\n",
    "        return  accuracy\n",
    "    \n",
    "    def run_all(self,model,df_X_toPredict,train_y,TopTarget_Pick_pred,class_DistFrPick_TopTarget):\n",
    "        self.predict_from_model(model,df_X_toPredict)\n",
    "        return self.accuracy_calc(train_y,TopTarget_Pick_pred,class_DistFrPick_TopTarget)\n",
    "\n",
    "\n",
    "#### Example of use of function above:\n",
    "##### Creating a class_accuracy instance with the already established ML1 variable for an isntance of the ML_obj_class\n",
    "#ac = class_accuracy(ML1)\n",
    "\n",
    "################## Class Prediction Results for training dataframe for X #############\n",
    "\n",
    "##### Creating a class_accuracy instance with the already established ML1 variable for an isntance of the ML_obj_class\n",
    "# ac = class_accuracy(ML1)\n",
    "\n",
    "################## First with training data #############\n",
    "\n",
    "#### Running the accuracy calculation using the model trained on training data against training data. \n",
    "#### Testing how well the model predicts the class of each point, with class being categorized distance from actual pick.\n",
    "# accuracy = ac.run_all(model,ac.train_X,ac.train_y,'TopTarget_Pick_pred','class_DistFrPick_TopTarget')\n",
    "\n",
    "# print(\"accuracy of training dataset\",accuracy)\n",
    "\n",
    "################## Then with test data ###############\n",
    "\n",
    "#### Running the accuracy calculation using the model trained on training data against TEST data. \n",
    "#### Testing how well the model predicts the class of each point, with class being categorized distance from actual pick.\n",
    "# accuracy = ac.run_all(model,ac.test_X,ac.test_y,'TopTarget_Pick_pred','class_DistFrPick_TopTarget')\n",
    "\n",
    "# print(\"accuracy of test dataset\",accuracy)\n",
    "\n",
    "####################################### THIS IS TEST FOR ACCURACY OVER ALL ROWS, WHICH WE REALLY DON\"T CARE ABOUT ##########\n",
    "############ WE CARE ABOUT THE PICK ############################\n",
    "\n",
    "# New class for functions that take in point by point distance class prediction and use rolling window and other methods to pick which point should be the top in question\n",
    "# Make a few different columns classifiers that get the rolling mean of pick classifiers within different windows.\n",
    "# This will help compare a class prediction of 95 in one part of the well to a class prediction of 95 in a nother part of the well. The assumption being the right prediction will have not just one 100 or 95 prediction but several in close proximity where as the false predictions are more likely to be by themselves:\n",
    "\n",
    "#     Median\n",
    "#     Rolling mean 6\n",
    "#     Rolling mean 12\n",
    "#     Rolling Mean 20\n",
    "#     Sums of rolling all means\n",
    "\n",
    "########  In the future, it would be nice to calculate error bars as well!!!!!    ##########\n",
    "\n",
    "\n",
    "##################### The next part will attempt to go from classifiers of  ##################### \n",
    "#####################  (at, near, or far away from the pick in each well) to a single depth prediction for the pick in each well ###################### \n",
    "#####################  Class for calculating accuracy of single pick prediction in each well vs. #####################  \n",
    "######################  known pick based on rolling average & median ranking of depths with distance class #####################  \n",
    "#####################  predictions of being close to pick. #####################  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class InputDistClassPrediction_to_BestDepthForTop():\n",
    "    \"\"\"\n",
    "    Explain theyself\n",
    "    \"\"\"\n",
    "    def __init__(self,output_data_inst):\n",
    "        self.result_df_dist_class_prediction = None\n",
    "        self.concat_modelResults_w_indexValues = None\n",
    "        self.df_results_trainOrtest_wIndex = None\n",
    "        self.model = None\n",
    "        self.MLobj = None\n",
    "        self.result_df_dist_class_prediction = None\n",
    "    \n",
    "    def help(self):\n",
    "        print(\" eventually there will some sort of help printed here to explain this function more and how it is envisioned you wil run it. In other words, step 1, step 2, etc.\")\n",
    "    \n",
    "    def load_MLobj(self,MLobj):\n",
    "        self.MLobj = MLobj\n",
    "        print(\"loaded model into object instance\")\n",
    "        \n",
    "    def predict_from_model(self,model,df_X_toPredict):\n",
    "        \"\"\"\n",
    "        The predict_from_model function takes as argument a model that is already trained on training data, in the demo case a \n",
    "        scikit-learn XGBoost model and the dataframe of the columns to predict. From this, it fills in \n",
    "        the self.result_df_from_prediction attribute and returns nothing.\n",
    "    \n",
    "        \"\"\"\n",
    "        self.result_df_dist_class_prediction = model.predict(df_X_toPredict)\n",
    "        if type(self.result_df_dist_class_prediction) == None:\n",
    "            print(\"this function didn't work, self.distClassDF_wRollingCols_training is not populated with anything but None\")\n",
    "        else:\n",
    "            print(\"ran predict_from_model() which runs inside self.result_df_dist_class_prediction = model.predict(df_X_toPredict) access the results by appending .result_df_dist_class_prediction to the class instance\")\n",
    "        return self.result_df_dist_class_prediction\n",
    "\n",
    "        \n",
    "    def load_dist_class_pred_df(self,dist_class_pred_df):\n",
    "        \"\"\"\n",
    "        explain theyself\n",
    "        \"\"\"\n",
    "#         if self.result_df_dist_class_prediction == None:\n",
    "        self.result_df_dist_class_prediction = dist_class_pred_df\n",
    "#         else:\n",
    "#             print(\"trying to replace earlier result_df_dist_class_prediction\")\n",
    "        \n",
    "    \n",
    "    def concat_modelResultsNDArray_w_indexValues(self,distClassModel_resultsNDArry,train_or_test,col_name_prediction):\n",
    "        #### self,self.result_df_dist_class_prediction,\"test\",vs.pick_class_str\n",
    "        if(train_or_test == 'train'):\n",
    "            y_indexValues = self.MLobj.train_y.index.values\n",
    "            train_or_test_y = self.MLobj.train_y\n",
    "        else:\n",
    "            y_indexValues = self.MLobj.test_y.index.values\n",
    "            train_or_test_y = self.MLobj.test_y\n",
    "        print(type(distClassModel_resultsNDArry))\n",
    "        print(type(y_indexValues))\n",
    "        if len(distClassModel_resultsNDArry) != len(y_indexValues):\n",
    "            print(\"Two input arguments length does not match. This invalidates an assumption of this function\")\n",
    "            print(\"length of distClassModel_resultsNDArry is \",len(distClassModel_resultsNDArry),\" and length of y_indexValues\",len(y_indexValues))\n",
    "        else:\n",
    "            #y_indexValues = train_or_test_y.index.values\n",
    "            # df_result = pd.DataFrame(result_test, index=test_y_indexValues, columns=['TopTarget_Pick_pred'])\n",
    "            df_result = pd.DataFrame(distClassModel_resultsNDArry, index=y_indexValues, columns=[col_name_prediction])\n",
    "            df_results_test_ = pd.concat([train_or_test_y,df_result], axis=1)\n",
    "            self.concat_modelResults_w_indexValues = df_results_test_\n",
    "            return self.concat_modelResults_w_indexValues\n",
    "            \n",
    "    def concat_step2(self,MLobj,train_or_test,cols_to_keep_list):\n",
    "        #### cols_to_keep_list = ['DEPT',\"NN1_TopHelper_DEPTH\",\"NN1_thickness\",\"topTarget_Depth_predBy_NN1thick\",\"DistFrom_NN1ThickPredTopDepth_toRowDept\"]\n",
    "        if(train_or_test == 'train'):\n",
    "            TrainOrTest_index = MLobj.train_index\n",
    "            df_ = self.MLobj.train_X\n",
    "        else:\n",
    "            TrainOrTest_index = MLobj.test_index\n",
    "            df_ = self.MLobj.test_X\n",
    "        df_results_test_ = self.concat_modelResults_w_indexValues\n",
    "        df_results_test_wIndex = pd.concat([df_results_test_, TrainOrTest_index], axis=1)\n",
    "        df_results_test_wIndex2 = pd.concat([df_results_test_wIndex, df_[cols_to_keep_list]], axis=1)\n",
    "        self.df_results_trainOrtest_wIndex = df_results_test_wIndex2\n",
    "        print(\"in concat_step2, type of df_results_trainOrtest_wIndex=\",type(self.df_results_trainOrtest_wIndex))\n",
    "        return self.df_results_trainOrtest_wIndex\n",
    "        \n",
    "    \n",
    "    def calc_pred_vs_real_top_dif(self,df,depth_str,pick_pred_class_str,UWI_str,rollingWindows,predClasses):\n",
    "        \"\"\"\n",
    "        Function takes in:\n",
    "            A dataframe with predictions and dataframe with UWIs and known pick depths. Dataframes may not be same length but df 2 must have all UWIs in df 1.\n",
    "        Function returns:\n",
    "            A column for predicted dataframe with calculated single prediction depth pick based on the median row technique\n",
    "            A column for predicted dataframe with calculated single prediction depth pick based on rolling means of classes predicted for each row.\n",
    "        THESE BELOW ARE NOTE YET IMPLIMENTED!    \n",
    "            A new dataframe that is just one row per well and includes as col of UWIs, known picks, predicted picks, and difference\n",
    "            A new col in the new df that has high and low error by some metric?\n",
    "            A score of mean abosolute error across all wells in the given dataframe 1.\n",
    "        \"\"\"\n",
    "\n",
    "        df_merges = df.copy()\n",
    "        all_new_rolling_mean_col = []\n",
    "        for Window in rollingWindows:\n",
    "            new_col = pick_pred_class_str+'_classRollMean'+str(Window)\n",
    "            all_new_rolling_mean_col.append(new_col)\n",
    "            half_window_neg = -1*math.floor(Window/2)\n",
    "            df_merges[new_col] = df_merges.groupby([UWI_str])[pick_pred_class_str].shift(half_window_neg).rolling(Window).mean().fillna(0)\n",
    "        df_merges[pick_pred_class_str+'classRollMeanSum'] = 0\n",
    "        for col in all_new_rolling_mean_col:\n",
    "            df_merges[pick_pred_class_str+'classRollMeanSum'] += df_merges[col]\n",
    "        df_merges[pick_pred_class_str+'classRollMeanSum'] += df_merges[pick_pred_class_str].astype(float)\n",
    "        idx = df_merges.loc[df_merges.groupby([\"UWI\"])[pick_pred_class_str+'classRollMeanSum'].idxmax()] \n",
    "        #print('idx=',idx)\n",
    "        print('type(idx)',type(idx))\n",
    "        #     print(idx[['UWI','DEPT',pick_pred_class_str+'classRollMeanSum']])\n",
    "        max_frame = idx[['UWI','DEPT',pick_pred_class_str+'classRollMeanSum']]\n",
    "        max_frame.columns = ['UWI',pick_pred_class_str+'_DEPT_pred',pick_pred_class_str+'_classRollMeanSum']\n",
    "        #print(\"type\",type(max_series),\"and max series is \",max_series)\n",
    "        df_merges = pd.merge(df_merges,max_frame, on='UWI', how='outer')\n",
    "        return df_merges\n",
    "    \n",
    "                       #ML1,model,\"test\",         vs,cols_to_keep_list,concatClass_test.df_results_trainOrtest_wIndex,vs.depth_str,vs.pick_class_str,vs.UWI_str,vs.rollingWindows,vs.distClassIntegersArray\n",
    "    def run_all(self,MLobj,model,trainOrTest_str,cols_to_keep_list,depth_str,pick_pred_class_str,UWI_str,rollingWindows,predClasses):\n",
    "        \"\"\"\n",
    "        Runs two functions. Takes in first the resulting dataframe from model.predict(df_X_toPredict). Take in second, depth_str,pick_pred_class_str,UWI_str,rollingWindows,predClasses.\n",
    "        Creates rolling means and median distance class values across different size rolling windows.\n",
    "        \"\"\"\n",
    "        ## \n",
    "        self.load_MLobj(MLobj)\n",
    "        if trainOrTest_str == 'train':\n",
    "            self.predict_from_model(model,MLobj.train_X)\n",
    "        else:\n",
    "            self.predict_from_model(model,MLobj.test_X)\n",
    "        #self.load_dist_class_pred_df(dist_class_pred_df)\n",
    "        self.concat_modelResultsNDArray_w_indexValues(self.result_df_dist_class_prediction,trainOrTest_str,pick_pred_class_str)\n",
    "        self.concat_step2(MLobj,trainOrTest_str,cols_to_keep_list)\n",
    "        \n",
    "        ##\n",
    "        dist_class_pred_df = self.df_results_trainOrtest_wIndex\n",
    "        print(\"type of dist_class_pred_df\",type(dist_class_pred_df))\n",
    "        print(\"type of self.df_results_trainOrtest_wIndex\",type(self.df_results_trainOrtest_wIndex))\n",
    "        \n",
    "        df_merges = self.calc_pred_vs_real_top_dif(self.df_results_trainOrtest_wIndex,depth_str,pick_pred_class_str,UWI_str,rollingWindows,predClasses)\n",
    "        return df_merges\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class accuracy_singleTopPerWellPrediction_fromRollingRules():\n",
    "    \"\"\"\n",
    "    stuff here\n",
    "    calculates accuracy on a per well basis after doing some rolling mean analysis on per depth point scores from machine-learning classification of distance class.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    \n",
    "    def __init__(self,ML, vs,distClassDF_wRollingCols_training):\n",
    "        # self.knn_dir = ML.knn_dir\n",
    "        # self.load_dir = ML.load_dir\n",
    "        # self.features_dir = ML.features_dir\n",
    "        # self.machine_learning_dir = ML.machine_learning_dir\n",
    "        # self.h5_to_load = ML.h5_to_load \n",
    "        self.train_X = ML.train_X\n",
    "        self.train_y = ML.train_y\n",
    "        self.test_X = ML.test_X\n",
    "        self.test_y = ML.test_y\n",
    "        self.train_index = ML.train_index\n",
    "        self.test_index = ML.test_index\n",
    "        self.preSplitpreBal = ML.preSplitpreBal\n",
    "        self.result_df_from_prediction = None #df\n",
    "        ####\n",
    "        ####\n",
    "        self.vs = vs # object instance from variables class\n",
    "        self.depth_str = vs[\"depth_str\"]\n",
    "        self.pick_class_str = vs[\"pick_class_str\"]\n",
    "        self.UWI_str = vs[\"UWI_str\"]\n",
    "        self.rollingWindows = vs[\"rollingWindows\"]\n",
    "        self.distClassIntegersArray = vs[\"distClassIntegersArray\"]\n",
    "        ####\n",
    "        self.calc_pred = distClassDF_wRollingCols_training\n",
    "        self.excludeWellsThatOnlyHaveTheseClasses = [] ### aka dropIfOnlyClasses in optionallyExcludeWellsWithoutStrongPredictions()\n",
    "        self.NoGoodWellsToExclude = [] #### UWIs of wells that only had zeros in the predicted dsitance class so these wells were excluded from accurracy prediction\n",
    "        ####\n",
    "        self.calc_pred_TopMcMr_Pick_pred_DEPT_pred = None #df\n",
    "        self.calc_pred_TopTarget_DEPTH = None #df\n",
    "        self.fullUWIsSet = [] ### set of UWIs in the dataframe\n",
    "        self.precentWellsKept = 1\n",
    "        self.UWIsSetSubsetKept = [] #### subset of the wells that have predictions that aren't just zero or something else not wanted\n",
    "        \n",
    "    ## if zeros, calc_pred is changed to without zeros and zerosExcluded Array is populated\n",
    "    \n",
    "    \n",
    "    def help(self):\n",
    "        print(\" eventually there will some sort of help printed here to explain this function more and how it is envisioned you wil run it. In other words, step 1, step 2, etc.\")\n",
    "        \n",
    "    def load_variables_obj(vs):\n",
    "        #vs.depth_str,vs.pick_class_str,vs.UWI_str\n",
    "        self.vs = vs\n",
    "        print(\"variables loaded include:\",list(vs.keys()))\n",
    "        \n",
    "    def optionallyExcludeWellsWithoutStrongPredictions(self,keepAllWells=None,dropIfOnlyClasses=[0]):\n",
    "        # [0,60,70,95,100]\n",
    "        self.excludeWellsThatOnlyHaveTheseClasses = dropIfOnlyClasses\n",
    "        if keepAllWells == \"no\":\n",
    "            calc_pred = self.calc_pred\n",
    "            self.fullUWIsSet = calc_pred[self.UWI_str].unique()\n",
    "            for eachClass in dropIfOnlyClasses:\n",
    "                calc_pred = calc_pred.loc[calc_pred['TopTarget_Pick_pred_classRollMeanSum'] != eachClass]\n",
    "            #calc_pred_noZeros = calc_pred.loc[calc_pred['TopTarget_Pick_pred_classRollMeanSum'] != 0]\n",
    "            self.UWIsSetSubsetKept = calc_pred[self.UWI_str].unique()\n",
    "            \n",
    "            self.calc_pred = calc_pred\n",
    "            print(\"hit yes in optionallyExcludeWellsWithoutStrongPredictions()\")\n",
    "        else:\n",
    "            calc_pred = self.calc_pred\n",
    "            self.fullUWIsSet = calc_pred[self.UWI_str].unique()\n",
    "            self.UWIsSetSubsetKept = calc_pred[self.UWI_str].unique()\n",
    "            #uniqueVals = df[\"cluster\"].unique()\n",
    "            print(\"hit pass in optionallyExcludeWellsWithoutStrongPredictions()\")\n",
    "        self.precentWellsKept = len(self.UWIsSetSubsetKept) / len(self.fullUWIsSet)\n",
    "    \n",
    "    def reduceDFtoOneBestTopPredictionPerWell(self,TopTarget_Pick_pred_DEPT_pred):\n",
    "        ## TopTarget_Pick_pred_DEPT_pred = 'TopTarget_Pick_pred_DEPT_pred'\n",
    "        \"\"\"\n",
    "        THINGS GO HERE\n",
    "        \"\"\"\n",
    "        self.TopTarget_Pick_pred_DEPT_pred = TopTarget_Pick_pred_DEPT_pred\n",
    "        df = self.calc_pred\n",
    "        self.calc_pred_Top_Pick_pred_DEPT_pred = df.groupby( [self.UWI_str])[TopTarget_Pick_pred_DEPT_pred].mean().to_frame().reset_index()\n",
    "        \n",
    "    def reduceDFtoOriginalTopPerWell(self,TopTarget_DEPTH):\n",
    "        ## TopTarget_DEPTH = 'TopTarget_DEPTH'\n",
    "        \"\"\"\n",
    "        THINGS GO HERE\n",
    "        \"\"\"\n",
    "        df = self.calc_pred\n",
    "        self.TopTarget_DEPTH = TopTarget_DEPTH\n",
    "        self.calc_pred_TopTarget_DEPTH = df.groupby( [self.UWI_str] )[TopTarget_DEPTH].mean().to_frame().reset_index()\n",
    "\n",
    "    def r2_func(self):\n",
    "        \"\"\"\n",
    "        THINGS GO HERE\n",
    "        \"\"\"\n",
    "        r2_ = r2_score(self.calc_pred_TopTarget_DEPTH[self.TopTarget_DEPTH], self.calc_pred_Top_Pick_pred_DEPT_pred[self.TopTarget_Pick_pred_DEPT_pred])\n",
    "        return r2_\n",
    "    \n",
    "    def mean_absolute_error_func(self):\n",
    "        \"\"\"\n",
    "        THINGS GO HERE\n",
    "        \"\"\"\n",
    "        #self.TopTarget_DEPTH\n",
    "        print(type(self.calc_pred_TopTarget_DEPTH))\n",
    "        print(type(self.calc_pred_TopTarget_DEPTH[self.TopTarget_DEPTH]))\n",
    "        print(type(self.calc_pred_Top_Pick_pred_DEPT_pred))\n",
    "        print(type(self.calc_pred_Top_Pick_pred_DEPT_pred[self.TopTarget_Pick_pred_DEPT_pred]))\n",
    "        print(type(self.TopTarget_DEPTH))\n",
    "        print(type(self.TopTarget_Pick_pred_DEPT_pred))\n",
    "        mean_absolute_error_ = mean_absolute_error(self.calc_pred_TopTarget_DEPTH[self.TopTarget_DEPTH], self.calc_pred_Top_Pick_pred_DEPT_pred[self.TopTarget_Pick_pred_DEPT_pred])\n",
    "        \n",
    "        #mean_absolute_error_ = mean_absolute_error(self.calc_pred_TopTarget_DEPTH[self.TopTarget_DEPTH], self.calc_pred_Top_Pick_pred_DEPT_pred[self.TopTarget_Pick_pred_DEPT_pred])\n",
    "        \n",
    "        #mean_absolute_error_ = mean_absolute_error(self.calc_pred_TopTarget_DEPTH['TopTarget_DEPTH'], self.calc_pred_Top_Pick_pred_DEPT_pred['TopTarget_Pick_pred_DEPT_pred'])\n",
    "        \n",
    "        return mean_absolute_error_\n",
    "    \n",
    "    def compare_RealTop_vsTopFromRollingMean(self):\n",
    "        \"\"\"\n",
    "        things go here\n",
    "        \"\"\"\n",
    "        new_diff_col = 'diff_'+str(self.TopTarget_DEPTH)+\"_-_\"+str(self.TopTarget_Pick_pred_DEPT_pred)\n",
    "        self.calc_pred_Top_Pick_pred_DEPT_pred[new_diff_col] = self.calc_pred_TopTarget_DEPTH[self.TopTarget_DEPTH] - self.calc_pred_Top_Pick_pred_DEPT_pred[self.TopTarget_Pick_pred_DEPT_pred]\n",
    "        self.calc_pred_Top_Pick_pred_DEPT_pred[self.TopTarget_DEPTH] = self.calc_pred_TopTarget_DEPTH[self.TopTarget_DEPTH]\n",
    "        #### line below prints histogram\n",
    "        self.calc_pred_Top_Pick_pred_DEPT_pred.hist(column=new_diff_col,bins=80,figsize=(15,5))\n",
    "    \n",
    "    \n",
    "    def run_all(self,TopTarget_Pick_pred_DEPT_pred,TopTarget_DEPTH,keepAllWells=\"no\",dropIfOnlyClasses=[0]):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        ####\n",
    "        self.optionallyExcludeWellsWithoutStrongPredictions(keepAllWells,dropIfOnlyClasses)\n",
    "        self.reduceDFtoOneBestTopPredictionPerWell(TopTarget_Pick_pred_DEPT_pred)\n",
    "        print(\"1\")\n",
    "        self.reduceDFtoOriginalTopPerWell(TopTarget_DEPTH)\n",
    "        print(\"2\")\n",
    "#         self.reduceDFtoOneBestTopPredictionPerWell(TopTarget_DEPTH,TopTarget_Pick_pred_DEPT_pred)\n",
    "#         print(\"3\")\n",
    "#         self.reduceDFtoOriginalTopPerWell(df)\n",
    "        print(\"4\")\n",
    "        r2__ = self.r2_func()\n",
    "        #mean = mean_absolute_error_ = mean_absolute_error(self.calc_pred_TopTarget_DEPTH[self.TopTarget_DEPTH], self.calc_pred_Top_Pick_pred_DEPT_pred[self.TopTarget_Pick_pred_DEPT_pred])\n",
    "        mean_absolute_error_ = self.mean_absolute_error_func()\n",
    "        self.compare_RealTop_vsTopFromRollingMean()\n",
    "        \n",
    "        return r2__,mean_absolute_error_,self.calc_pred_Top_Pick_pred_DEPT_pred\n",
    "\n",
    "\n",
    "def saveRebalanceResultsAsHDF(df_testPlusRebalTrain_featWithHighCount, train_X, train_y, test_X, test_y, train_index, test_index, output_data_inst):\n",
    "    \"\"\"\n",
    "    Takes in \n",
    "    Saves \n",
    "    Returns \n",
    "    \"\"\"\n",
    "    ###### Establish file path to save \n",
    "    load_dir = output_data_inst.base_path_for_all_results+ \"/\" + output_data_inst.path_balance\n",
    "    load_results_full_file_path = load_dir+\"/\"+output_data_inst.balance_results_wells_df+output_data_inst.default_results_file_format\n",
    "    #########################  Write each pandas dataframes to single HDF5 using separate keys to retrieve later\n",
    "    df_testPlusRebalTrain_featWithHighCount.to_hdf(load_results_full_file_path, key='preSplitpreBal', mode='w')\n",
    "    train_X.to_hdf(load_results_full_file_path, key='train_X')\n",
    "    train_y.to_hdf(load_results_full_file_path, key='train_y')\n",
    "    test_X.to_hdf(load_results_full_file_path, key='test_X')\n",
    "    test_y.to_hdf(load_results_full_file_path, key='test_y')\n",
    "    train_index.to_hdf(load_results_full_file_path, key='train_index')\n",
    "    test_index.to_hdf(load_results_full_file_path, key='test_index')\n",
    "    print(\"finished saving the results of the rebalancing script in the location set in the output class instance. = \",load_results_full_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import predictionclasses \n",
    "from configurationplusfiles_runner import input_data_inst, config, output_data_inst\n",
    "from main import getJobLibPickleResults\n",
    "\n",
    "\n",
    "\n",
    "################## Load model & ML class instance from trainclasses step #############\n",
    "\n",
    "# model = getJobLibPickleResults(output_data_inst,output_data_inst.path_trainclasses,\"trainclasses_model.pkl\")\n",
    "# ML1 = getJobLibPickleResults(output_data_inst,output_data_inst.path_trainclasses,\"trainclasses_ML1_instance.pkl\")\n",
    "\n",
    "model,ML1 =loadMLinstanceAndModel(output_data_inst)\n",
    "\n",
    "print(\"the model imported is:\",model)\n",
    "\n",
    "################## Class Prediction Results for training dataframe for X #############\n",
    "\n",
    "##### Creating a class_accuracy instance with the already established ML1 variable for an isntance of the ML_obj_class\n",
    "ac = class_accuracy(ML1)\n",
    "\n",
    "\n",
    "################## First with training data #############\n",
    "\n",
    "#### Running the accuracy calculation using the model trained on training data against training data. \n",
    "#### Testing how well the model predicts the class of each point, with class being categorized distance from actual pick.\n",
    "accuracy_train = ac.run_all(model,ac.train_X,ac.train_y,'TopTarget_Pick_pred','class_DistFrPick_TopTarget')\n",
    "\n",
    "print(\"accuracy of training dataset\",accuracy_train)\n",
    "\n",
    "\n",
    "################## Then with test data ###############\n",
    "\n",
    "#### Running the accuracy calculation using the model trained on training data against TEST data. \n",
    "#### Testing how well the model predicts the class of each point, with class being categorized distance from actual pick.\n",
    "accuracy_test = ac.run_all(model,ac.test_X,ac.test_y,'TopTarget_Pick_pred','class_DistFrPick_TopTarget')\n",
    "\n",
    "print(\"accuracy of test dataset\",accuracy_test)\n",
    "\n",
    "\n",
    "####################################### THIS IS TEST FOR ACCURACY OVER ALL ROWS, WHICH WE REALLY DON\"T CARE ABOUT ##########\n",
    "############ WE CARE ABOUT THE PICK ############################\n",
    "\n",
    "# New class for functions that take in point by point distance class prediction and use rolling window and other methods to pick which point should be the top in question\n",
    "# Make a few different columns classifiers that get the rolling mean of pick classifiers within different windows.\n",
    "# This will help compare a class prediction of 95 in one part of the well to a class prediction of 95 in a nother part of the well. The assumption being the right prediction will have not just one 100 or 95 prediction but several in close proximity where as the false predictions are more likely to be by themselves:\n",
    "\n",
    "#     Median\n",
    "#     Rolling mean 6\n",
    "#     Rolling mean 12\n",
    "#     Rolling Mean 20\n",
    "#     Sums of rolling all means\n",
    "\n",
    "\n",
    "concatClass = InputDistClassPrediction_to_BestDepthForTop(output_data_inst)\n",
    "\n",
    "concatClass.load_MLobj(ML1)\n",
    "\n",
    "concatClass.help()\n",
    "\n",
    "prediction_distClass_trainingData_ndarray = concatClass.predict_from_model(model,ML1.train_X)\n",
    "\n",
    "concatClass1 = concatClass.concat_modelResultsNDArray_w_indexValues(concatClass.result_df_dist_class_prediction,\"train\",config.pick_class_str)\n",
    "\n",
    "\n",
    "##### NEED TO PUT THIS LIST IN CONFIG ########## !!!!!!!\n",
    "cols_to_keep_list = ['DEPT',\"NN1_TopHelper_DEPTH\",\"NN1_thickness\",\"topTarget_Depth_predBy_NN1thick\",\"DistFrom_NN1ThickPredTopDepth_toRowDept\"]\n",
    "\n",
    "concatClass2 = concatClass.concat_step2(ML1,\"train\",cols_to_keep_list)\n",
    "\n",
    "#####\n",
    "DEPTH_col_in_featureCreation = config.DEPTH_col_in_featureCreation\n",
    "pick_class_str = config.pick_class_str\n",
    "UWI = config.UWI\n",
    "curve_windows_for_rolling_features = config.curve_windows_for_rolling_features\n",
    "label_intergers = list(config.zonesAroundTops.keys())\n",
    "\n",
    "distClassDF_wRollingCols_training = concatClass.calc_pred_vs_real_top_dif(concatClass.df_results_trainOrtest_wIndex,DEPTH_col_in_featureCreation,pick_class_str,UWI,curve_windows_for_rolling_features,label_intergers)\n",
    "\n",
    "\n",
    "print(\"distClassDF_wRollingCols_training.head() = \",distClassDF_wRollingCols_training.head())\n",
    "\n",
    "print(\"printing distClassDF_wRollingCols_training for checking that it makes sense::\",distClassDF_wRollingCols_training.tail())\n",
    "\n",
    "################ Now lets run test version   ################\n",
    "\n",
    "concatClass_test = InputDistClassPrediction_to_BestDepthForTop(output_data_inst)\n",
    "\n",
    "\n",
    "#####\n",
    "DEPTH_col_in_featureCreation = config.DEPTH_col_in_featureCreation\n",
    "pick_class_str = config.pick_class_str\n",
    "UWI = config.UWI\n",
    "curve_windows_for_rolling_features = config.curve_windows_for_rolling_features\n",
    "label_intergers = list(config.zonesAroundTops.keys())\n",
    "\n",
    "\n",
    "\n",
    "#### Doing it the 'all at once' way this time.\n",
    "distClassDF_wRollingCols_testData = concatClass_test.run_all(ML1,model,\"test\",cols_to_keep_list,DEPTH_col_in_featureCreation,pick_class_str,UWI,curve_windows_for_rolling_features,label_intergers)\n",
    "\n",
    "print(\"distClassDF_wRollingCols_testData.head()\",distClassDF_wRollingCols_testData.head())\n",
    "\n",
    "##################### The next part will attempt to go from classifiers of  ##################### \n",
    "#####################  (at, near, or far away from the pick in each well) to a single depth prediction for the pick in each well ###################### \n",
    "#####################  Class for calculating accuracy of single pick prediction in each well vs. #####################  \n",
    "######################  known pick based on rolling average & median ranking of depths with distance class #####################  \n",
    "#####################  predictions of being close to pick. #####################  \n",
    "\n",
    "vs = {\"depth_str\":config.DEPTH_col_in_featureCreation,\"pick_class_str\":config.pick_class_str,\"UWI_str\" :config.UWI,\"rollingWindows\":config.curve_windows_for_rolling_features,\"distClassIntegersArray\" :list(config.zonesAroundTops.keys())}\n",
    "print(\"vs\",vs)\n",
    "print(\"gap\")\n",
    "print(\"vs\",vs[\"depth_str\"])\n",
    "\n",
    "\n",
    "#####################  Start accuracy_singleTopPerWellPrediction_fromRollingRules() class for training data  #####################  \n",
    "\n",
    "rollToWell = accuracy_singleTopPerWellPrediction_fromRollingRules(ML1,vs,distClassDF_wRollingCols_training)\n",
    "\n",
    "r2,mean_absolute_error_,df_calc_pred_Top_Pick_pred_DEPT_pred = rollToWell.run_all('TopTarget_Pick_pred_DEPT_pred','TopTarget_DEPTH',keepAllWells=\"yes\",dropIfOnlyClasses=[0])\n",
    "\n",
    "\n",
    "print(\"len(df_calc_pred_Top_Pick_pred_DEPT_pred\",len(df_calc_pred_Top_Pick_pred_DEPT_pred))\n",
    "print(\"r2 of training dataset in terms of pick depths = \",r2)\n",
    "print(\"mean_absolute_error_ of training dataset in terms of pick depths = \",mean_absolute_error_)\n",
    "\n",
    "print(\"percent of wells kept because they weren't just class zero in rollToWell function for training:\",rollToWell.precentWellsKept)\n",
    "\n",
    "#####################  Now accuracy for test dataset again via accuracy_singleTopPerWellPrediction_fromRollingRules()  #####################  \n",
    "\n",
    "#####################  First we'll do it and keep all wells not matter whether or not they include any class predictions other than zero  #####################  \n",
    "#####################  This will include some wells with some very bad predictions as there are not class predictions to go off of #####################  \n",
    "\n",
    "\n",
    "rollToWell_test = accuracy_singleTopPerWellPrediction_fromRollingRules(ML1,vs,distClassDF_wRollingCols_testData)\n",
    "r2_test,mean_absolute_error_test,df_calc_pred_Top_Pick_pred_DEPT_pred2 = rollToWell_test.run_all('TopTarget_Pick_pred_DEPT_pred','TopTarget_DEPTH',keepAllWells=\"yes\",dropIfOnlyClasses=[0])\n",
    "\n",
    "print(\"r2 for test and all wells kept is:\",r2_test)\n",
    "print(\"mean_absolute_error_test for test and all wells kept is:\",mean_absolute_error_test)\n",
    "print(\"percent wells kept for test and all wells kept is:\",rollToWell_test.precentWellsKept)\n",
    "\n",
    "#####################  Now let's try it for test dataset but exclude wells that only have a zero class prediction #####################  \n",
    "\n",
    "rollToWell_test_NoZeros = accuracy_singleTopPerWellPrediction_fromRollingRules(ML1,vs,distClassDF_wRollingCols_testData)\n",
    "r2_test_NoZeros ,mean_absolute_error_test_NoZeros ,df_calc_pred_Top_Pick_pred_DEPT_pred2_NoZeros  = rollToWell_test_NoZeros .run_all('TopTarget_Pick_pred_DEPT_pred','TopTarget_DEPTH',keepAllWells=\"no\",dropIfOnlyClasses=[0])\n",
    "\n",
    "print(\"r2 for test and wells excluded that only had zero class predicted is:\",r2_test_NoZeros)\n",
    "print(\"mean_absolute_error_test for test and wells excluded that only had zero class predicted is:\",mean_absolute_error_test_NoZeros)\n",
    "print(\"percent wells kept for test and wells excluded that only had zero class predicted is:\",rollToWell_test_NoZeros.precentWellsKept)\n",
    "\n",
    "number_of_wells_thrown_out = len(rollToWell_test_NoZeros.fullUWIsSet) - len(rollToWell_test_NoZeros.fullUWIsSet)*rollToWell_test_NoZeros.precentWellsKept\n",
    "\n",
    "print(\"number of wells with only zeros predicted that were thrown out:\",number_of_wells_thrown_out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import predictionclasses_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
