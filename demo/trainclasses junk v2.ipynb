{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking_for_right_len_in_balance.ipynb\r\n",
      "Junk - experimentation .ipynb\r\n",
      "Junk - experimentation 2.ipynb\r\n",
      "Junk - experimentation 3 - features & balance.ipynb\r\n",
      "balance junk v1.ipynb\r\n",
      "current_errors_TopMcMr_20181006.png\r\n",
      "\u001b[34mmannville_demo_data\u001b[m\u001b[m/\r\n",
      "predictionclasses junk v1.ipynb\r\n",
      "test junk.ipynb\r\n",
      "trainclasses junk v1.ipynb\r\n",
      "trainclasses junk v2.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justingosses/anaconda/envs/MannvilleDask2/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/justingosses/anaconda/envs/MannvilleDask2/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/justingosses/Code/predictatops\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPG_Abstract_2019ACE.md  README_0.rst              requirements.txt\r\n",
      "AUTHORS.rst               \u001b[34m__pycache__\u001b[m\u001b[m/              requirements_dev.txt\r\n",
      "CONTRIBUTING.rst          \u001b[34mdata\u001b[m\u001b[m/                     \u001b[34mresults\u001b[m\u001b[m/\r\n",
      "HISTORY.rst               \u001b[34mdemo\u001b[m\u001b[m/                     setup.cfg\r\n",
      "LICENSE                   \u001b[34mdocs\u001b[m\u001b[m/                     setup.py\r\n",
      "MANIFEST.in               environment.yml           \u001b[34mtests\u001b[m\u001b[m/\r\n",
      "Makefile                  \u001b[34mpredictatops\u001b[m\u001b[m/             tox.ini\r\n",
      "README.md                 \u001b[34mpredictatops.egg-info\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/justingosses/Code/predictatops/predictatops\n"
     ]
    }
   ],
   "source": [
    "cd predictatops/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainclasses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of picks df =      SitID  HorID      Pick  Quality\n",
      "0  102496   1000       321        1\n",
      "1  102496   2000                 -1\n",
      "2  102496   3000                 -1\n",
      "3  102496   4000                 -1\n",
      "4  102496   5000       438        2\n",
      "making base folder for results in: ../results\n",
      "base_path directory already exists, ../results  so not creating it again. This may or may not be what you intended, so just flagging it.\n",
      "directory  checkData  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  load  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  split  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  wellKNN  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  features  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  balance  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  trainclasses  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  prediction  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  evaluate  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "directory  map  already exists so not making it again in make_all_directories function of configurationplusfiles.py\n",
      "made directories for each step in the process. They should be in :  ../results\n",
      "must have curve list is:  ['ILD', 'NPHI', 'GR', 'DPHI', 'DEPT']\n",
      "set must_have_tops_list as:  [13000, 14000]\n",
      " set self.top_name_col_in_picks_df as:  HorID\n",
      "config.siteID_col_in_picks_df =  SitID\n",
      "all config is {'csv_of_well_names_wTopsCuves__name': '', 'csv_of_well_names_wTopCurves__path': '.', 'must_have_curves_list': ['ILD', 'NPHI', 'GR', 'DPHI', 'DEPT'], 'curve_windows_for_rolling_features': [5, 7, 11, 21], 'must_have_tops__list': [13000, 14000], 'target_top': 13000, 'top_under_target': 14000, 'top_name_col_in_picks_df': 'HorID', 'siteID_col_in_picks_df': 'SitID', 'UWI': 'UWI', 'DEPTH_col_in_featureCreation': 'DEPT', 'HorID_name_col_in_picks_df': 'HorID', 'quality_col_name_in_picks_df': 'Quality', 'picks_depth_col_in_picks_df': 'Pick', 'col_topTarget_Depth_predBy_NN1thick': 'topTarget_Depth_predBy_NN1thick', 'quality_items_to_skip__list': [-1, 0], 'test': 'test0', 'pick_class_str': 'TopTarget_Pick_pred', 'threshold_returnCurvesThatArePresentInThisManyWells': 2000, 'max_numb_wells_to_load': 1000000, 'split_traintest_percent': 0.8, 'kdtree_leaf': 2, 'kdtree_k': 8, 'NN1_topTarget_DEPTH': 'NN1_topTarget_DEPTH', 'NN1_TopHelper_DEPTH': 'NN1_TopHelper_DEPTH', 'trainOrTest': 'trainOrTest', 'colsToNotTurnToFloats': ['UWI', 'SitID', 'trainOrTest', 'Neighbors_Obj'], 'zonesAroundTops': {'100': [0], '95': [-0.5, 0.5], '60': [-5, 0.5], '70': [0.5, 5], '0': []}, 'columns_to_not_trainOn_andNotCurves': ['FromBotWell', 'FromTopWelrowsToEdge', 'lat', 'lng', 'SitID', 'TopHelper_HorID', 'TopTarget_HorID', 'TopHelper_DEPTH', 'diff_Top_Depth_Real_v_predBy_NN1thick', 'diff_TopTarget_DEPTH_v_rowDEPT', 'diff_TopHelper_DEPTH_v_rowDEPT', 'class_DistFrPick_TopHelper', 'NewWell', 'LastBitWell', 'TopWellDept', 'BotWellDept', 'WellThickness', 'rowsToEdge', 'closTopBotDist', 'closerToBotOrTop', 'Neighbors_Obj'], 'columns_to_not_trainOn_andAreCurves': ['RHOB', 'SP', 'CALI', 'COND', 'DELT', 'DENS', 'DPHI:1', 'DPHI:2', 'DT', 'GR:1', 'GR:2', 'IL', 'ILD:1', 'ILD:2', 'ILM', 'LITH', 'LLD', 'LLS', 'PHID', 'PHIN', 'RESD', 'RT', 'SFL', 'SFLU', 'SN', 'SNP', 'Sp'], 'columns_to_use_as_labels': ['class_DistFrPick_TopTarget', 'UWI', 'trainOrTest', 'TopTarget_DEPTH']}\n"
     ]
    }
   ],
   "source": [
    "################ import from other python files in this package ###################\n",
    "from trainclasses import *\n",
    "from configurationplusfiles_runner import input_data_inst, config, output_data_inst\n",
    "from main import get_df_results_from_step_X, getMainDFsavedInStep, load_prev_results_at_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML1 = ML_obj_class(output_data_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED: test_X and test_y and test_index are all the same size as asserted 261260\n",
      "PASSED: train_X and train_y and train_index are all the same size as asserted 225243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Loading the h5 format data into pandas finished. You may access the dataframes by appending to the ML1 object .train_X | .train_y | test_X | .test_y | .train_index | .test_index | .preSplitpreBal'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML1.load_data_for_ml()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors_Obj not found in column so taken out earlier or not included so doesn't have to be taken out\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ML1.dropNeighbors_ObjCol(\"Neighbors_Obj\")\n",
    "except:\n",
    "    print(\"Neighbors_Obj not found in column so taken out earlier or not included so doesn't have to be taken out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing the preSplitpreBal df head that was saved in the balance part of the workflow.\n",
      "ML1.train_X.columns Index(['DEPT', 'DPHI', 'GR', 'ILD', 'NPHI', 'TopHelper_HorID_Qual', 'TopTarget_Qual', 'NN1_topTarget_DEPTH', 'NN1_TopHelper_DEPTH', 'NN1_thickness',\n",
      "       ...\n",
      "       'DEPT_min_11winSize_dirAbovenLarge', 'DEPT_min_11winSize_dirAroundnLarge', 'DEPT_min_21winSize_dirAroundMin', 'DEPT_min_21winSize_dirAboveMin', 'DEPT_min_21winSize_dirAroundMax', 'DEPT_min_21winSize_dirAboveMax', 'DEPT_min_21winSize_dirAroundMean', 'DEPT_min_21winSize_dirAboveMean', 'DEPT_min_21winSize_dirAbovenLarge', 'DEPT_min_21winSize_dirAroundnLarge'], dtype='object', length=174)\n"
     ]
    }
   ],
   "source": [
    "print(\"printing the preSplitpreBal df head that was saved in the balance part of the workflow.\")\n",
    "ML1.preSplitpreBal.head()\n",
    "\n",
    "# ML1.preSplitpreBal = ML1.preSplitpreBal[0:50000]\n",
    "# ML1.train_X = ML1.train_X[0:50000]\n",
    "# ML1.train_y = ML1.train_y[0:50000]\n",
    "# ML1.test_X = ML1.test_X[0:50000]\n",
    "# ML1.test_y = ML1.test_y[0:50000]\n",
    "print(\"ML1.train_X.columns\",ML1.train_X.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns_X = list(ML1.train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_columns_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEPT',\n",
       " 'DPHI',\n",
       " 'GR',\n",
       " 'ILD',\n",
       " 'NPHI',\n",
       " 'TopHelper_HorID_Qual',\n",
       " 'TopTarget_Qual',\n",
       " 'NN1_topTarget_DEPTH',\n",
       " 'NN1_TopHelper_DEPTH',\n",
       " 'NN1_thickness',\n",
       " 'topTarget_Depth_predBy_NN1thick',\n",
       " 'DistFrom_NN1ThickPredTopDepth_toRowDept',\n",
       " 'FromTopWell',\n",
       " 'diff_DEPT_vs_NN1_topTarget_DEPTH',\n",
       " 'ILD_min_5winSize_dirAroundMin',\n",
       " 'ILD_min_5winSize_dirAboveMin',\n",
       " 'ILD_min_5winSize_dirAroundMax',\n",
       " 'ILD_min_5winSize_dirAboveMax',\n",
       " 'ILD_min_5winSize_dirAroundMean',\n",
       " 'ILD_min_5winSize_dirAboveMean',\n",
       " 'ILD_min_5winSize_dirAbovenLarge',\n",
       " 'ILD_min_5winSize_dirAroundnLarge',\n",
       " 'ILD_min_7winSize_dirAroundMin',\n",
       " 'ILD_min_7winSize_dirAboveMin',\n",
       " 'ILD_min_7winSize_dirAroundMax',\n",
       " 'ILD_min_7winSize_dirAboveMax',\n",
       " 'ILD_min_7winSize_dirAroundMean',\n",
       " 'ILD_min_7winSize_dirAboveMean',\n",
       " 'ILD_min_7winSize_dirAbovenLarge',\n",
       " 'ILD_min_7winSize_dirAroundnLarge',\n",
       " 'ILD_min_11winSize_dirAroundMin',\n",
       " 'ILD_min_11winSize_dirAboveMin',\n",
       " 'ILD_min_11winSize_dirAroundMax',\n",
       " 'ILD_min_11winSize_dirAboveMax',\n",
       " 'ILD_min_11winSize_dirAroundMean',\n",
       " 'ILD_min_11winSize_dirAboveMean',\n",
       " 'ILD_min_11winSize_dirAbovenLarge',\n",
       " 'ILD_min_11winSize_dirAroundnLarge',\n",
       " 'ILD_min_21winSize_dirAroundMin',\n",
       " 'ILD_min_21winSize_dirAboveMin',\n",
       " 'ILD_min_21winSize_dirAroundMax',\n",
       " 'ILD_min_21winSize_dirAboveMax',\n",
       " 'ILD_min_21winSize_dirAroundMean',\n",
       " 'ILD_min_21winSize_dirAboveMean',\n",
       " 'ILD_min_21winSize_dirAbovenLarge',\n",
       " 'ILD_min_21winSize_dirAroundnLarge',\n",
       " 'NPHI_min_5winSize_dirAroundMin',\n",
       " 'NPHI_min_5winSize_dirAboveMin',\n",
       " 'NPHI_min_5winSize_dirAroundMax',\n",
       " 'NPHI_min_5winSize_dirAboveMax',\n",
       " 'NPHI_min_5winSize_dirAroundMean',\n",
       " 'NPHI_min_5winSize_dirAboveMean',\n",
       " 'NPHI_min_5winSize_dirAbovenLarge',\n",
       " 'NPHI_min_5winSize_dirAroundnLarge',\n",
       " 'NPHI_min_7winSize_dirAroundMin',\n",
       " 'NPHI_min_7winSize_dirAboveMin',\n",
       " 'NPHI_min_7winSize_dirAroundMax',\n",
       " 'NPHI_min_7winSize_dirAboveMax',\n",
       " 'NPHI_min_7winSize_dirAroundMean',\n",
       " 'NPHI_min_7winSize_dirAboveMean',\n",
       " 'NPHI_min_7winSize_dirAbovenLarge',\n",
       " 'NPHI_min_7winSize_dirAroundnLarge',\n",
       " 'NPHI_min_11winSize_dirAroundMin',\n",
       " 'NPHI_min_11winSize_dirAboveMin',\n",
       " 'NPHI_min_11winSize_dirAroundMax',\n",
       " 'NPHI_min_11winSize_dirAboveMax',\n",
       " 'NPHI_min_11winSize_dirAroundMean',\n",
       " 'NPHI_min_11winSize_dirAboveMean',\n",
       " 'NPHI_min_11winSize_dirAbovenLarge',\n",
       " 'NPHI_min_11winSize_dirAroundnLarge',\n",
       " 'NPHI_min_21winSize_dirAroundMin',\n",
       " 'NPHI_min_21winSize_dirAboveMin',\n",
       " 'NPHI_min_21winSize_dirAroundMax',\n",
       " 'NPHI_min_21winSize_dirAboveMax',\n",
       " 'NPHI_min_21winSize_dirAroundMean',\n",
       " 'NPHI_min_21winSize_dirAboveMean',\n",
       " 'NPHI_min_21winSize_dirAbovenLarge',\n",
       " 'NPHI_min_21winSize_dirAroundnLarge',\n",
       " 'GR_min_5winSize_dirAroundMin',\n",
       " 'GR_min_5winSize_dirAboveMin',\n",
       " 'GR_min_5winSize_dirAroundMax',\n",
       " 'GR_min_5winSize_dirAboveMax',\n",
       " 'GR_min_5winSize_dirAroundMean',\n",
       " 'GR_min_5winSize_dirAboveMean',\n",
       " 'GR_min_5winSize_dirAbovenLarge',\n",
       " 'GR_min_5winSize_dirAroundnLarge',\n",
       " 'GR_min_7winSize_dirAroundMin',\n",
       " 'GR_min_7winSize_dirAboveMin',\n",
       " 'GR_min_7winSize_dirAroundMax',\n",
       " 'GR_min_7winSize_dirAboveMax',\n",
       " 'GR_min_7winSize_dirAroundMean',\n",
       " 'GR_min_7winSize_dirAboveMean',\n",
       " 'GR_min_7winSize_dirAbovenLarge',\n",
       " 'GR_min_7winSize_dirAroundnLarge',\n",
       " 'GR_min_11winSize_dirAroundMin',\n",
       " 'GR_min_11winSize_dirAboveMin',\n",
       " 'GR_min_11winSize_dirAroundMax',\n",
       " 'GR_min_11winSize_dirAboveMax',\n",
       " 'GR_min_11winSize_dirAroundMean',\n",
       " 'GR_min_11winSize_dirAboveMean',\n",
       " 'GR_min_11winSize_dirAbovenLarge',\n",
       " 'GR_min_11winSize_dirAroundnLarge',\n",
       " 'GR_min_21winSize_dirAroundMin',\n",
       " 'GR_min_21winSize_dirAboveMin',\n",
       " 'GR_min_21winSize_dirAroundMax',\n",
       " 'GR_min_21winSize_dirAboveMax',\n",
       " 'GR_min_21winSize_dirAroundMean',\n",
       " 'GR_min_21winSize_dirAboveMean',\n",
       " 'GR_min_21winSize_dirAbovenLarge',\n",
       " 'GR_min_21winSize_dirAroundnLarge',\n",
       " 'DPHI_min_5winSize_dirAroundMin',\n",
       " 'DPHI_min_5winSize_dirAboveMin',\n",
       " 'DPHI_min_5winSize_dirAroundMax',\n",
       " 'DPHI_min_5winSize_dirAboveMax',\n",
       " 'DPHI_min_5winSize_dirAroundMean',\n",
       " 'DPHI_min_5winSize_dirAboveMean',\n",
       " 'DPHI_min_5winSize_dirAbovenLarge',\n",
       " 'DPHI_min_5winSize_dirAroundnLarge',\n",
       " 'DPHI_min_7winSize_dirAroundMin',\n",
       " 'DPHI_min_7winSize_dirAboveMin',\n",
       " 'DPHI_min_7winSize_dirAroundMax',\n",
       " 'DPHI_min_7winSize_dirAboveMax',\n",
       " 'DPHI_min_7winSize_dirAroundMean',\n",
       " 'DPHI_min_7winSize_dirAboveMean',\n",
       " 'DPHI_min_7winSize_dirAbovenLarge',\n",
       " 'DPHI_min_7winSize_dirAroundnLarge',\n",
       " 'DPHI_min_11winSize_dirAroundMin',\n",
       " 'DPHI_min_11winSize_dirAboveMin',\n",
       " 'DPHI_min_11winSize_dirAroundMax',\n",
       " 'DPHI_min_11winSize_dirAboveMax',\n",
       " 'DPHI_min_11winSize_dirAroundMean',\n",
       " 'DPHI_min_11winSize_dirAboveMean',\n",
       " 'DPHI_min_11winSize_dirAbovenLarge',\n",
       " 'DPHI_min_11winSize_dirAroundnLarge',\n",
       " 'DPHI_min_21winSize_dirAroundMin',\n",
       " 'DPHI_min_21winSize_dirAboveMin',\n",
       " 'DPHI_min_21winSize_dirAroundMax',\n",
       " 'DPHI_min_21winSize_dirAboveMax',\n",
       " 'DPHI_min_21winSize_dirAroundMean',\n",
       " 'DPHI_min_21winSize_dirAboveMean',\n",
       " 'DPHI_min_21winSize_dirAbovenLarge',\n",
       " 'DPHI_min_21winSize_dirAroundnLarge',\n",
       " 'DEPT_min_5winSize_dirAroundMin',\n",
       " 'DEPT_min_5winSize_dirAboveMin',\n",
       " 'DEPT_min_5winSize_dirAroundMax',\n",
       " 'DEPT_min_5winSize_dirAboveMax',\n",
       " 'DEPT_min_5winSize_dirAroundMean',\n",
       " 'DEPT_min_5winSize_dirAboveMean',\n",
       " 'DEPT_min_5winSize_dirAbovenLarge',\n",
       " 'DEPT_min_5winSize_dirAroundnLarge',\n",
       " 'DEPT_min_7winSize_dirAroundMin',\n",
       " 'DEPT_min_7winSize_dirAboveMin',\n",
       " 'DEPT_min_7winSize_dirAroundMax',\n",
       " 'DEPT_min_7winSize_dirAboveMax',\n",
       " 'DEPT_min_7winSize_dirAroundMean',\n",
       " 'DEPT_min_7winSize_dirAboveMean',\n",
       " 'DEPT_min_7winSize_dirAbovenLarge',\n",
       " 'DEPT_min_7winSize_dirAroundnLarge',\n",
       " 'DEPT_min_11winSize_dirAroundMin',\n",
       " 'DEPT_min_11winSize_dirAboveMin',\n",
       " 'DEPT_min_11winSize_dirAroundMax',\n",
       " 'DEPT_min_11winSize_dirAboveMax',\n",
       " 'DEPT_min_11winSize_dirAroundMean',\n",
       " 'DEPT_min_11winSize_dirAboveMean',\n",
       " 'DEPT_min_11winSize_dirAbovenLarge',\n",
       " 'DEPT_min_11winSize_dirAroundnLarge',\n",
       " 'DEPT_min_21winSize_dirAroundMin',\n",
       " 'DEPT_min_21winSize_dirAboveMin',\n",
       " 'DEPT_min_21winSize_dirAroundMax',\n",
       " 'DEPT_min_21winSize_dirAboveMax',\n",
       " 'DEPT_min_21winSize_dirAroundMean',\n",
       " 'DEPT_min_21winSize_dirAboveMean',\n",
       " 'DEPT_min_21winSize_dirAbovenLarge',\n",
       " 'DEPT_min_21winSize_dirAroundnLarge']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns_X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now starting to make the model. If none given, parameters that worked well for the top McMurray pick will be used.\n",
      "default model parameters provided are: gamma=0, reg_alpha=0.3, max_depth=6, subsample=0.8, colsample_bytree= 0.8, n_estimators= 300, learning_rate= 0.03, min_child_weight= 3,n_jobs=8\n",
      " init_XGBoost_withSettings function has been called which initiates a XGBoost classifier with settings of : max_depth=4,objective='multi:softmax', training,num_class=5,n_gpus= 0,n_jobs=8\n",
      "model coming out of init_XGBoost_withSettings() function is: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=4, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_gpus=0, n_jobs=8, nthread=None, num_class=5,\n",
      "       objective='multi:softmax', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Now starting to make the model. If none given, parameters that worked well for the top McMurray pick will be used.\")\n",
    "print(\"default model parameters provided are: gamma=0, reg_alpha=0.3, max_depth=6, subsample=0.8, colsample_bytree= 0.8, n_estimators= 300, learning_rate= 0.03, min_child_weight= 3,n_jobs=8\")\n",
    "\n",
    "model = ML1.init_XGBoost_withSettings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-11 17:34:30.027786\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now fitting the model to the training data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_gpus=0, n_jobs=8, nthread=None, num_class=5,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"now fitting the model to the training data:\")\n",
    "model.fit(ML1.train_X,ML1.train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just to show what model contains a bit:\n",
      "type(model) <class 'xgboost.sklearn.XGBClassifier'>\n",
      "model stats XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=4, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_gpus=0, n_jobs=8, nthread=None, num_class=5,\n",
      "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1)\n",
      "model.subsample 1\n"
     ]
    }
   ],
   "source": [
    "############ just to show what model contains a bit  ###########\n",
    "\n",
    "print(\"just to show what model contains a bit:\")\n",
    "\n",
    "print(\"type(model)\",type(model))\n",
    "\n",
    "print(\"model stats\",model)\n",
    "\n",
    "print(\"model.subsample\",model.subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "############   Optionally loading the already trained model here if it already exists locally.   ############ \n",
    "############   It can take quite a while to fit the model, so sometimes easier to save a copy and then load it.   ############ \n",
    "\n",
    "######################### WRITE FUNCTION FOR THIS !!!!!! ####################\n",
    "######################### Something like: model = pickle.load(open(\"classModel_20181122a.pickle.dat\", \"rb\")) & print(type(model))\n",
    "\n",
    "#model = pickle.load(open(\"classModel_20181122a.pickle.dat\", \"rb\")) & print(type(model))\n",
    "\n",
    "#saveTrainClassesResultsAsHDF(model,output_data_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished saving the results of the model step in the location set in the output class instance. =  ../results/trainclasses/trainclasses_model.pkl\n"
     ]
    }
   ],
   "source": [
    "saveTrainClassesResultsAsPickle(model,ML1,output_data_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-11 17:41:45.373588\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW MOVING TO predictionclasses.py file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from predictionclasses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MannvilleDask2]",
   "language": "python",
   "name": "conda-env-MannvilleDask2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
